{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cac8e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0629a2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "attrition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "business_travel",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "daily_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "department",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "distance_from_home",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education_field",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "employee_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "environment_satisfaction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hourly_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "job_involvement",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_role",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_satisfaction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "marital_status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "monthly_income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "monthly_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_companies_worked",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "overtime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "percent_salary_hike",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "performance_rating",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "relationship_satisfaction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "standard_hours",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stock_option_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_working_years",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "training_times_last_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_life_balance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "years_at_company",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "years_since_last_promotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "years_with_curr_manager",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date_birth",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "salary",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "remote_work",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "iter_hourly_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iter_total_working_years",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iter_monthly_income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iter_salary",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "knn_hourly_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "knn_total_working_years",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "knn_monthly_income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "knn_salary",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "351afaac-8a19-42fd-a1d9-8b41855b88b2",
       "rows": [
        [
         "0",
         "51",
         "no",
         null,
         "2015.72",
         null,
         "6",
         "3",
         null,
         "1",
         "low",
         "female",
         "251.96724093925093",
         "high",
         "executive",
         "research_director",
         "high",
         null,
         "16280.83",
         "42330.17",
         "7",
         "no",
         "13",
         "3,0",
         "high",
         "full_time",
         "0",
         "30.03974379822701",
         "5",
         "good",
         "20",
         "15",
         "15",
         "1972",
         "195370.0",
         "yes",
         "83.042301980198",
         "11.318933823529411",
         "16280.83",
         "195370.0",
         "83.042301980198",
         "11.318933823529411",
         "16280.83",
         "195370.0"
        ],
        [
         "1",
         "52",
         "no",
         null,
         "2063.39",
         null,
         "1",
         "4",
         "life_sciences",
         "2",
         "high",
         "female",
         "257.92581201460246",
         "medium",
         "executive",
         "manager",
         "high",
         null,
         "17117.127782767457",
         "43331.17",
         "0",
         "no",
         "14",
         "3,0",
         "low",
         "part_time",
         "1",
         "34.0",
         "5",
         "good",
         "33",
         "11",
         "9",
         "1971",
         "199990.0",
         "yes",
         "83.042301980198",
         "34.0",
         "5697.60022687609",
         "199990.0",
         "83.042301980198",
         "34.0",
         "5697.60022687609",
         "199990.0"
        ],
        [
         "2",
         "42",
         "no",
         "travel_rarely",
         "1984.25",
         "research_&_development",
         "4",
         "2",
         "technical_degree",
         "3",
         "high",
         "female",
         "248.0333527886016",
         "high",
         "executive",
         "manager",
         "very_high",
         "married",
         "16468.2521203622",
         "41669.33",
         "1",
         "no",
         "11",
         "3,0",
         "very_high",
         "part_time",
         "0",
         "22.0",
         "3",
         "good",
         "22",
         "11",
         "15",
         "1981",
         "192320.0",
         "yes",
         "83.042301980198",
         "22.0",
         "5697.60022687609",
         "192320.0",
         "83.042301980198",
         "22.0",
         "5697.60022687609",
         "192320.0"
        ],
        [
         "3",
         "47",
         "no",
         "travel_rarely",
         "1771.4",
         null,
         "2",
         "4",
         "medical",
         "4",
         "low",
         "male",
         "221.42699808455063",
         "high",
         "manager",
         "research_director",
         "high",
         "married",
         "14307.5",
         "37199.5",
         "3",
         "no",
         "19",
         "3,0",
         "medium",
         "full_time",
         "2",
         "26.672706874982943",
         "2",
         "good",
         "20",
         "5",
         "6",
         "1976",
         "171690.0",
         "no",
         "83.042301980198",
         "11.318933823529411",
         "14307.5",
         "171690.0",
         "83.042301980198",
         "11.318933823529411",
         "14307.5",
         "171690.0"
        ],
        [
         "4",
         "46",
         "no",
         null,
         "1582.77",
         null,
         "3",
         "3",
         "technical_degree",
         "5",
         "low",
         "male",
         "102.95816226378092",
         "very_high",
         "manager",
         "sales_executive",
         "low",
         "divorced",
         "12783.92",
         "33238.2",
         "2",
         "no",
         "12",
         "3,0",
         "very_high",
         "part_time",
         "1",
         "11.260714768989104",
         "5",
         "good",
         "19",
         "2",
         "8",
         "1977",
         "79832.80474607903",
         "no",
         "83.042301980198",
         "11.318933823529411",
         "12783.92",
         "65245.87531343283",
         "83.042301980198",
         "11.318933823529411",
         "12783.92",
         "65245.87531343283"
        ]
       ],
       "shape": {
        "columns": 43,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>attrition</th>\n",
       "      <th>business_travel</th>\n",
       "      <th>daily_rate</th>\n",
       "      <th>department</th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>education</th>\n",
       "      <th>education_field</th>\n",
       "      <th>employee_number</th>\n",
       "      <th>environment_satisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>salary</th>\n",
       "      <th>remote_work</th>\n",
       "      <th>iter_hourly_rate</th>\n",
       "      <th>iter_total_working_years</th>\n",
       "      <th>iter_monthly_income</th>\n",
       "      <th>iter_salary</th>\n",
       "      <th>knn_hourly_rate</th>\n",
       "      <th>knn_total_working_years</th>\n",
       "      <th>knn_monthly_income</th>\n",
       "      <th>knn_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>195370.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>16280.830000</td>\n",
       "      <td>195370.000000</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>16280.830000</td>\n",
       "      <td>195370.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2063.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>life_sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>199990.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>5697.600227</td>\n",
       "      <td>199990.000000</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>5697.600227</td>\n",
       "      <td>199990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>no</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>1984.25</td>\n",
       "      <td>research_&amp;_development</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>technical_degree</td>\n",
       "      <td>3</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>192320.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5697.600227</td>\n",
       "      <td>192320.000000</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5697.600227</td>\n",
       "      <td>192320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>no</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>1771.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>medical</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>171690.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>14307.500000</td>\n",
       "      <td>171690.000000</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>14307.500000</td>\n",
       "      <td>171690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1582.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>technical_degree</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>79832.804746</td>\n",
       "      <td>no</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>12783.920000</td>\n",
       "      <td>65245.875313</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>12783.920000</td>\n",
       "      <td>65245.875313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age attrition business_travel  daily_rate              department  \\\n",
       "0   51        no             NaN     2015.72                     NaN   \n",
       "1   52        no             NaN     2063.39                     NaN   \n",
       "2   42        no   travel_rarely     1984.25  research_&_development   \n",
       "3   47        no   travel_rarely     1771.40                     NaN   \n",
       "4   46        no             NaN     1582.77                     NaN   \n",
       "\n",
       "   distance_from_home  education   education_field  employee_number  \\\n",
       "0                   6          3               NaN                1   \n",
       "1                   1          4     life_sciences                2   \n",
       "2                   4          2  technical_degree                3   \n",
       "3                   2          4           medical                4   \n",
       "4                   3          3  technical_degree                5   \n",
       "\n",
       "  environment_satisfaction  ...         salary  remote_work iter_hourly_rate  \\\n",
       "0                      low  ...  195370.000000          yes        83.042302   \n",
       "1                     high  ...  199990.000000          yes        83.042302   \n",
       "2                     high  ...  192320.000000          yes        83.042302   \n",
       "3                      low  ...  171690.000000           no        83.042302   \n",
       "4                      low  ...   79832.804746           no        83.042302   \n",
       "\n",
       "  iter_total_working_years iter_monthly_income    iter_salary knn_hourly_rate  \\\n",
       "0                11.318934        16280.830000  195370.000000       83.042302   \n",
       "1                34.000000         5697.600227  199990.000000       83.042302   \n",
       "2                22.000000         5697.600227  192320.000000       83.042302   \n",
       "3                11.318934        14307.500000  171690.000000       83.042302   \n",
       "4                11.318934        12783.920000   65245.875313       83.042302   \n",
       "\n",
       "   knn_total_working_years  knn_monthly_income     knn_salary  \n",
       "0                11.318934        16280.830000  195370.000000  \n",
       "1                34.000000         5697.600227  199990.000000  \n",
       "2                22.000000         5697.600227  192320.000000  \n",
       "3                11.318934        14307.500000  171690.000000  \n",
       "4                11.318934        12783.920000   65245.875313  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23867e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'attrition', 'business_travel', 'daily_rate', 'department',\n",
       "       'distance_from_home', 'education', 'education_field', 'employee_number',\n",
       "       'environment_satisfaction', 'gender', 'hourly_rate', 'job_involvement',\n",
       "       'job_level', 'job_role', 'job_satisfaction', 'marital_status',\n",
       "       'monthly_income', 'monthly_rate', 'num_companies_worked', 'overtime',\n",
       "       'percent_salary_hike', 'performance_rating',\n",
       "       'relationship_satisfaction', 'standard_hours', 'stock_option_level',\n",
       "       'total_working_years', 'training_times_last_year', 'work_life_balance',\n",
       "       'years_at_company', 'years_since_last_promotion',\n",
       "       'years_with_curr_manager', 'date_birth', 'salary', 'remote_work',\n",
       "       'iter_hourly_rate', 'iter_total_working_years', 'iter_monthly_income',\n",
       "       'iter_salary', 'knn_hourly_rate', 'knn_total_working_years',\n",
       "       'knn_monthly_income', 'knn_salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8dd988",
   "metadata": {},
   "source": [
    "# Creating tables\n",
    "\n",
    "Table 1 - Employees (primary_key: employee_number)    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 4 - education: education_id + education_category  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 5 - education_field: education_field_id + education_field  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 7 - gender: gender_id + gender  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 10 - marital_status: marital_status_id + marital_status  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 12 - stock_option_level: stock_option_level_id + stock_option_level (numerica)\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tables - Salaries  \n",
    "\n",
    "->Table 2 - Identificador de trabajos Tipologias de trabajo  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 2 - business_travel: business_travel_id + business_travel_category  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 11 - standard_hours: standard_hours_id + standard_hours_category     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table - Remote work\n",
    "\n",
    "-> Table 3 - scale_1_4: scale_id + scale_level  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; environment_satisfaction   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; job_satisfaction  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; relationship_satisfaction   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; job_involvement  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 13 - work_life_balance: work_life_balance_id + work_life_balance_category    \n",
    "\n",
    "-> Table 4 - Department_Role  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 3 - department: department_id + department_name  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 8 - job_level: job_level_id + job_level  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 9 - job_role: job_role_id + job_role  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28908598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    travel_id  std_hours_id  remote_id  typology_id  \\\n",
      "0           1             1          1          111   \n",
      "1           1             1          2          112   \n",
      "2           1             2          1          121   \n",
      "3           1             2          2          122   \n",
      "4           2             1          1          211   \n",
      "5           2             1          2          212   \n",
      "6           2             2          1          221   \n",
      "7           2             2          2          222   \n",
      "8           3             1          1          311   \n",
      "9           3             1          2          312   \n",
      "10          3             2          1          321   \n",
      "11          3             2          2          322   \n",
      "12       <NA>             1          1           11   \n",
      "13       <NA>             1          2           12   \n",
      "14       <NA>             2          1           21   \n",
      "15       <NA>             2          2           22   \n",
      "\n",
      "                                    typology  \n",
      "0          non_travel, full_time, yes remote  \n",
      "1           non_travel, full_time, no remote  \n",
      "2          non_travel, part_time, yes remote  \n",
      "3           non_travel, part_time, no remote  \n",
      "4       travel_rarely, full_time, yes remote  \n",
      "5        travel_rarely, full_time, no remote  \n",
      "6       travel_rarely, part_time, yes remote  \n",
      "7        travel_rarely, part_time, no remote  \n",
      "8   travel_frequently, full_time, yes remote  \n",
      "9    travel_frequently, full_time, no remote  \n",
      "10  travel_frequently, part_time, yes remote  \n",
      "11   travel_frequently, part_time, no remote  \n",
      "12                     full_time, yes remote  \n",
      "13                      full_time, no remote  \n",
      "14                     part_time, yes remote  \n",
      "15                      part_time, no remote  \n"
     ]
    }
   ],
   "source": [
    "# Table 2 - Work Typologies\n",
    "# Create list of the typologies characteristics\n",
    "categories1 = df['business_travel'].unique().tolist()\n",
    "categories2 = df['standard_hours'].unique().tolist()\n",
    "categories3 = df['remote_work'].unique().tolist()\n",
    "\n",
    "# Create DataFrames (df) based on the litsts\n",
    "work_typologies1 = pd.DataFrame({'category_travel': categories1})\n",
    "work_typologies2 = pd.DataFrame({'category_std_hours': categories2})\n",
    "work_typologies3 = pd.DataFrame({'category_remote': categories3})\n",
    "\n",
    "# Create a mapping order for the characteristics\n",
    "order_mapping1 = {'non_travel': 1, 'travel_rarely': 2, 'travel_frequently': 3, 'NaN': 4}\n",
    "order_mapping2 = {'full_time': 1, 'part_time': 2, 'NaN': 3}\n",
    "order_mapping3 = {'yes': 1, 'no': 2, 'NaN': 3}\n",
    "\n",
    "# Sort using custom mapping\n",
    "work_typologies1 = work_typologies1.assign(sort_order = lambda work_typologies1: work_typologies1['category_travel'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "work_typologies2 = work_typologies2.assign(sort_order = lambda work_typologies2: work_typologies2['category_std_hours'].map(order_mapping2)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "work_typologies3 = work_typologies3.assign(sort_order = lambda work_typologies3: work_typologies3['category_remote'].map(order_mapping3)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "\n",
    "# Assign an _id\n",
    "work_typologies1.loc[work_typologies1['category_travel'] == 'non_travel', 'travel_id'] = 1\n",
    "work_typologies1.loc[work_typologies1['category_travel'] == 'travel_rarely', 'travel_id'] = 2\n",
    "work_typologies1.loc[work_typologies1['category_travel'] == 'travel_frequently', 'travel_id'] = 3\n",
    "\n",
    "work_typologies2.loc[work_typologies2['category_std_hours'] == 'full_time', 'std_hours_id'] = 1\n",
    "work_typologies2.loc[work_typologies2['category_std_hours'] == 'part_time', 'std_hours_id'] = 2\n",
    "\n",
    "\n",
    "work_typologies3.loc[work_typologies3['category_remote'] == 'yes', 'remote_id'] = 1\n",
    "work_typologies3.loc[work_typologies3['category_remote'] == 'no', 'remote_id'] = 2\n",
    "\n",
    "# Round _id, allowing for NaN values\n",
    "work_typologies1['travel_id'] = work_typologies1['travel_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "work_typologies2['std_hours_id'] = work_typologies2['std_hours_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "work_typologies3['remote_id'] = work_typologies3['remote_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "\n",
    "# Combine the characteristics\n",
    "cross_joined_df1 = work_typologies1.merge(work_typologies2, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df1.merge(work_typologies3, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df2.drop_duplicates()\n",
    "\n",
    "# Create typology_id based on characteristics' categories_id\n",
    "cross_joined_df2['typology_id'] = cross_joined_df2['travel_id']*100 + cross_joined_df2['std_hours_id']*10 + cross_joined_df2['remote_id'] \n",
    "mask = pd.isna(cross_joined_df2['typology_id'])\n",
    "cross_joined_df2.loc[mask, 'typology_id'] = (cross_joined_df2.loc[mask, 'std_hours_id'] * 10 + cross_joined_df2.loc[mask, 'remote_id'])\n",
    "\n",
    "# Create typology based on characteristics' categories\n",
    "cross_joined_df2['typology'] = cross_joined_df2['category_travel'] + ', ' + cross_joined_df2['category_std_hours']+ ', ' + cross_joined_df2['category_remote'] +' remote' \n",
    "mask = pd.isna(cross_joined_df2['typology'])\n",
    "cross_joined_df2.loc[mask, 'typology'] = (cross_joined_df2.loc[mask, 'category_std_hours'] + ', ' + cross_joined_df2.loc[mask, 'category_remote'] +' remote')\n",
    "\n",
    "print(cross_joined_df2[['travel_id','std_hours_id','remote_id','typology_id','typology']])\n",
    "\n",
    "table2 = cross_joined_df2.copy()\n",
    "table2.to_csv(\"typologies.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c774935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 - Satisfaction_and_involvment\n",
    "# Create list of the satisfaction characteristics\n",
    "categories1 = df['environment_satisfaction'].unique().tolist()\n",
    "categories2 = df['job_satisfaction'].unique().tolist()\n",
    "categories3 = df['job_involvement'].unique().tolist()\n",
    "categories4 = df['relationship_satisfaction'].unique().tolist()\n",
    "categories5 = df['work_life_balance'].unique().tolist()\n",
    "\n",
    "# Create DataFrames (df) based on the litsts\n",
    "satisfaction_typologies1 = pd.DataFrame({'category_environment': categories1})\n",
    "satisfaction_typologies2 = pd.DataFrame({'category_job_satisfaction': categories2})\n",
    "satisfaction_typologies3 = pd.DataFrame({'category_job_involvment': categories3})\n",
    "satisfaction_typologies4 = pd.DataFrame({'category_relationship': categories4})\n",
    "satisfaction_typologies5 = pd.DataFrame({'category_balance': categories5})\n",
    "\n",
    "# Create a mapping order for the characteristics\n",
    "order_mapping1 = {'low': 1, 'medium': 2, 'high': 3, 'very_high': 4, 'NaN': 5}\n",
    "order_mapping5 = {'very_low': 1, 'low': 2, 'good': 3, 'excellent': 4, 'NaN': 5}\n",
    "\n",
    "# Sort using custom mapping\n",
    "satisfaction_typologies1 = satisfaction_typologies1.assign(sort_order = lambda satisfaction_typologies1: satisfaction_typologies1['category_environment'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "satisfaction_typologies2 = satisfaction_typologies2.assign(sort_order = lambda satisfaction_typologies2: satisfaction_typologies2['category_job_satisfaction'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "satisfaction_typologies3 = satisfaction_typologies3.assign(sort_order = lambda satisfaction_typologies3: satisfaction_typologies3['category_job_involvment'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "satisfaction_typologies4 = satisfaction_typologies4.assign(sort_order = lambda satisfaction_typologies4: satisfaction_typologies4['category_relationship'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "satisfaction_typologies5 = satisfaction_typologies5.assign(sort_order = lambda satisfaction_typologies5: satisfaction_typologies5['category_balance'].map(order_mapping5)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "\n",
    "# Assign an _id\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'low', 'environment_id'] = 1\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'medium', 'environment_id'] = 2\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'high', 'environment_id'] = 3\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'very_high', 'environment_id'] = 4\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'NaN', 'environment_id'] = 5\n",
    "\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'low', 'job_satisfaction_id'] = 1\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'medium', 'job_satisfaction_id'] = 2\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'high', 'job_satisfaction_id'] = 3\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'very_high', 'job_satisfaction_id'] = 4\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'NaN', 'job_satisfaction_id'] = 5\n",
    "\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'low', 'job_involvment_id'] = 1\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'medium', 'job_involvment_id'] = 2\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'high', 'job_involvment_id'] = 3\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'very_high', 'job_involvment_id'] = 4\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'NaN', 'job_involvment_id'] = 5\n",
    "\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'low', 'relationship_id'] = 1\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'medium', 'relationship_id'] = 2\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'high', 'relationship_id'] = 3\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'very_high', 'relationship_id'] = 4\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'NaN', 'relationship_id'] = 4\n",
    "\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'very_low', 'balance_id'] = 1\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'low', 'balance_id'] = 2\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'good', 'balance_id'] = 3\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'excellent', 'balance_id'] = 4\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'NaN', 'balance_id'] = 5\n",
    "\n",
    "# Round _id, allowing for NaN values\n",
    "satisfaction_typologies1['environment_id'] = satisfaction_typologies1['environment_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "satisfaction_typologies2['job_satisfaction_id'] = satisfaction_typologies2['job_satisfaction_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "satisfaction_typologies3['job_involvment_id'] = satisfaction_typologies3['job_involvment_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "satisfaction_typologies4['relationship_id'] = satisfaction_typologies4['relationship_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "satisfaction_typologies5['balance_id'] = satisfaction_typologies5['balance_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "\n",
    "# Combine the characteristics\n",
    "cross_joined_df1 = satisfaction_typologies1.merge(satisfaction_typologies2, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df1.merge(satisfaction_typologies3, how = 'cross')\n",
    "cross_joined_df3 = cross_joined_df2.merge(satisfaction_typologies4, how = 'cross')\n",
    "cross_joined_df4 = cross_joined_df3.merge(satisfaction_typologies5, how = 'cross')\n",
    "cross_joined_df4 = cross_joined_df4.drop_duplicates()\n",
    "\n",
    "# Create typology_id based on characteristics' categories_id\n",
    "cross_joined_df4['satisfaction_id'] = (cross_joined_df4['environment_id']*10000 + cross_joined_df4['job_satisfaction_id']*1000 + cross_joined_df4['job_involvment_id']*100 + \n",
    "                                       cross_joined_df4['relationship_id']*10 + cross_joined_df4['balance_id']*1)\n",
    "mask = pd.isna(cross_joined_df4['satisfaction_id'])\n",
    "cross_joined_df4.loc[mask, 'satisfaction_id'] = (cross_joined_df4.loc[mask, 'job_satisfaction_id'] * 1000 + cross_joined_df4.loc[mask, 'job_involvment_id']*100 + \n",
    "                                             cross_joined_df4.loc[mask, 'relationship_id'] * 10 + cross_joined_df4.loc[mask, 'balance_id'] * 1)\n",
    "\n",
    "# Create typology based on characteristics' categories\n",
    "cross_joined_df4['satisfaction'] = (cross_joined_df4['category_environment'] + ', ' + cross_joined_df4['category_job_satisfaction']+ ', ' + cross_joined_df4['category_job_involvment'] +\n",
    "                                    ', ' + cross_joined_df4['category_relationship']+ ', ' + cross_joined_df4['category_balance'])\n",
    "mask = pd.isna(cross_joined_df4['satisfaction'])\n",
    "cross_joined_df4.loc[mask, 'satisfaction'] = ('environment_missing' + ' ,' + cross_joined_df4.loc[mask, 'category_job_satisfaction'] + ', ' + cross_joined_df4.loc[mask, 'category_job_involvment'] +\n",
    "                                              ', ' + cross_joined_df4.loc[mask, 'category_relationship'] + ', ' + cross_joined_df4.loc[mask, 'category_balance'])\n",
    "\n",
    "cross_joined_df4[['environment_id','job_satisfaction_id','job_involvment_id','relationship_id','balance_id', 'satisfaction_id', 'satisfaction']]\n",
    "\n",
    "table3 = cross_joined_df4.copy()\n",
    "table3.to_csv(\"satisfaction_involvment.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23347aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     department_id  level_id  role_id  department_role_id  \\\n",
      "0                1         1        1                 111   \n",
      "1                1         1        2                 112   \n",
      "2                1         1        3                 113   \n",
      "3                1         1        4                 114   \n",
      "4                1         1        5                 115   \n",
      "..             ...       ...      ...                 ...   \n",
      "175           <NA>         5        5                  55   \n",
      "176           <NA>         5        6                  56   \n",
      "177           <NA>         5        7                  57   \n",
      "178           <NA>         5        8                  58   \n",
      "179           <NA>         5        9                  59   \n",
      "\n",
      "                                       department_role  \n",
      "0    research_&_development, entry_level, research_...  \n",
      "1         research_&_development, entry_level, manager  \n",
      "2    research_&_development, entry_level, sales_exe...  \n",
      "3    research_&_development, entry_level, manufactu...  \n",
      "4    research_&_development, entry_level, research_...  \n",
      "..                                                 ...  \n",
      "175                         senior, research_scientist  \n",
      "176                  senior, healthcare_representative  \n",
      "177                      senior, laboratory_technician  \n",
      "178                       senior, sales_representative  \n",
      "179                            senior, human_resources  \n",
      "\n",
      "[180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Table 4 - Department_role\n",
    "# Create list of the department_role categories\n",
    "categories1 = df['department'].unique().tolist()\n",
    "categories2 = df['job_level'].unique().tolist()\n",
    "categories3 = df['job_role'].unique().tolist()\n",
    "\n",
    "# Create DataFrames (df) based on the litsts\n",
    "department_role1 = pd.DataFrame({'category_department': categories1})\n",
    "department_role2 = pd.DataFrame({'category_level': categories2})\n",
    "department_role3 = pd.DataFrame({'category_role': categories3})\n",
    "\n",
    "# Create a mapping order for the characteristics\n",
    "order_mapping1 = {'research_&_development': 1, 'sales': 2, 'human_resources': 3, 'NaN': 4}\n",
    "order_mapping2 = {'entry_level': 1, 'manager': 2, 'executive': 3, 'intermediate': 4, 'senior': 5, 'NaN': 6}\n",
    "order_mapping3 = {'research_director': 1, 'manager': 2, 'sales_executive': 3, 'manufacturing_director': 4, 'research_scientist': 5,\n",
    "                    'healthcare_representative': 6, 'laboratory_technician': 7, 'sales_representative': 8, 'human_resources': 9, 'NaN': 10}\n",
    "\n",
    "# Sort using custom mapping\n",
    "department_role1 = department_role1.assign(sort_order = lambda department_role1: department_role1['category_department'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "department_role2 = department_role2.assign(sort_order = lambda department_role2: department_role2['category_level'].map(order_mapping2)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "department_role3 = department_role3.assign(sort_order = lambda department_role3: department_role3['category_role'].map(order_mapping3)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "\n",
    "# Assign an _id\n",
    "department_role1.loc[department_role1['category_department'] == 'research_&_development', 'department_id'] = 1\n",
    "department_role1.loc[department_role1['category_department'] == 'sales', 'department_id'] = 2\n",
    "department_role1.loc[department_role1['category_department'] == 'human_resources', 'department_id'] = 3\n",
    "\n",
    "department_role2.loc[department_role2['category_level'] == 'entry_level', 'level_id'] = 1\n",
    "department_role2.loc[department_role2['category_level'] == 'manager', 'level_id'] = 2\n",
    "department_role2.loc[department_role2['category_level'] == 'executive', 'level_id'] = 3\n",
    "department_role2.loc[department_role2['category_level'] == 'intermediate', 'level_id'] = 4\n",
    "department_role2.loc[department_role2['category_level'] == 'senior', 'level_id'] = 5\n",
    "\n",
    "department_role3.loc[department_role3['category_role'] == 'research_director', 'role_id'] = 1\n",
    "department_role3.loc[department_role3['category_role'] == 'manager', 'role_id'] = 2\n",
    "department_role3.loc[department_role3['category_role'] == 'sales_executive', 'role_id'] = 3\n",
    "department_role3.loc[department_role3['category_role'] == 'manufacturing_director', 'role_id'] = 4\n",
    "department_role3.loc[department_role3['category_role'] == 'research_scientist', 'role_id'] = 5\n",
    "department_role3.loc[department_role3['category_role'] == 'healthcare_representative', 'role_id'] = 6\n",
    "department_role3.loc[department_role3['category_role'] == 'laboratory_technician', 'role_id'] = 7\n",
    "department_role3.loc[department_role3['category_role'] == 'sales_representative', 'role_id'] = 8\n",
    "department_role3.loc[department_role3['category_role'] == 'human_resources', 'role_id'] = 9\n",
    "\n",
    "# Round _id, allowing for NaN values\n",
    "department_role1['department_id'] = department_role1['department_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "department_role2['level_id'] = department_role2['level_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "department_role3['role_id'] = department_role3['role_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "\n",
    "# Combine the characteristics\n",
    "cross_joined_df1 = department_role1.merge(department_role2, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df1.merge(department_role3, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df2.drop_duplicates()\n",
    "\n",
    "# Create typology_id based on characteristics' categories_id\n",
    "cross_joined_df2['department_role_id'] = cross_joined_df2['department_id']*100 + cross_joined_df2['level_id']*10 + cross_joined_df2['role_id'] \n",
    "mask = pd.isna(cross_joined_df2['department_role_id'])\n",
    "cross_joined_df2.loc[mask, 'department_role_id'] = (cross_joined_df2.loc[mask, 'level_id'] * 10 + cross_joined_df2.loc[mask, 'role_id'])\n",
    "\n",
    "# Create typology based on characteristics' categories\n",
    "cross_joined_df2['department_role'] = cross_joined_df2['category_department'] + ', ' + cross_joined_df2['category_level']+ ', ' + cross_joined_df2['category_role'] \n",
    "mask = pd.isna(cross_joined_df2['department_role'])\n",
    "cross_joined_df2.loc[mask, 'department_role'] = (cross_joined_df2.loc[mask, 'category_level'] + ', ' + cross_joined_df2.loc[mask, 'category_role'])\n",
    "\n",
    "print(cross_joined_df2[['department_id','level_id','role_id','department_role_id','department_role']])\n",
    "\n",
    "table4 = cross_joined_df2.copy() \n",
    "table4.to_csv(\"department_role.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cff720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1\n",
    "df_employees = df.copy()\n",
    "df_employees.columns\n",
    "df_employees.rename(columns={\"business_travel\": \"category_travel\", \"standard_hours\": \"category_std_hours\", 'remote_work': 'category_remote',\n",
    "                   'environment_satisfaction': 'category_environment', 'job_satisfaction': 'category_job_satisfaction', 'job_involvement': 'category_job_involvment',\n",
    "                   'relationship_satisfaction': 'category_relationship', 'work_life_balance': 'category_balance',\n",
    "                   'department': 'category_department', 'job_level': 'category_level', 'job_role': 'category_role'}, inplace=True)\n",
    "\n",
    "\n",
    "df_employees = df_employees.merge(table2, on=['category_travel', 'category_std_hours', 'category_remote'], how='left')\n",
    "df_employees = df_employees.merge(table3, on=['category_environment', 'category_job_satisfaction', 'category_job_involvment', 'category_relationship', 'category_balance'], how='left')\n",
    "df_employees = df_employees.merge(table4, on=['category_department', 'category_level', 'category_role'], how='left')\n",
    "\n",
    "\n",
    "df_employees = df_employees.loc[:, ~df_employees.columns.str.startswith('category_')]\n",
    "\n",
    "columns = ['travel_id', 'std_hours_id', 'remote_id','environment_id', 'job_satisfaction_id', 'job_involvment_id','relationship_id',\n",
    "           'balance_id', 'department_id', 'level_id', 'role_id', 'typology','satisfaction','department_role']\n",
    "df_employees = df_employees.drop(columns=columns)\n",
    "\n",
    "table1 = df_employees.copy() \n",
    "table1.to_csv(\"employees.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "088dc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'root'\n",
    "password = 'AlumnaAdalab'\n",
    "host = '127.0.0.1'\n",
    "\n",
    "# Try the connection and check the error message and code in case it is not working\n",
    "try:\n",
    "  cnx = mysql.connector.connect(user = user, password = password,\n",
    "                                host = host)\n",
    "except mysql.connector.Error as err:\n",
    "  if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "    print(\"Something is wrong with your user name or password\")\n",
    "  elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "    print(\"Database does not exist\")\n",
    "  else:\n",
    "    print(err)\n",
    "else:\n",
    "  cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55ea88c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'project_talent' dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Connection parameters\n",
    "user = 'root'\n",
    "password = 'AlumnaAdalab'\n",
    "host = '127.0.0.1'\n",
    "\n",
    "# Connect to MySQL server\n",
    "cnx = mysql.connector.connect(user=user, password=password, host=host)\n",
    "mycursor = cnx.cursor()\n",
    "\n",
    "# Try to drop the database\n",
    "try:\n",
    "    mycursor.execute(\"DROP DATABASE project_talent\")\n",
    "    print(\"Database 'project_talent' dropped successfully.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Failed to drop database:\")\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)\n",
    "\n",
    "# Close connection\n",
    "mycursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddee0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMySQLCursor: CREATE DATABASE project_talent\n"
     ]
    }
   ],
   "source": [
    "user = 'root'\n",
    "password = 'AlumnaAdalab'\n",
    "host = '127.0.0.1'\n",
    "\n",
    "# conexión (1)\n",
    "cnx = mysql.connector.connect(user = user, password = password,\n",
    "                              host = host)\n",
    "\n",
    "# cursor (2)\n",
    "mycursor = cnx.cursor()\n",
    "\n",
    "try:\n",
    "    mycursor.execute(\"CREATE DATABASE project_talent\")\n",
    "    print(mycursor)\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3fec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age attrition  daily_rate  distance_from_home  education   education_field  \\\n",
      "0   51        no     2015.72                   6          3               NaN   \n",
      "1   52        no     2063.39                   1          4     life_sciences   \n",
      "2   42        no     1984.25                   4          2  technical_degree   \n",
      "3   47        no     1771.40                   2          4           medical   \n",
      "4   46        no     1582.77                   3          3  technical_degree   \n",
      "\n",
      "   employee_number  gender  hourly_rate marital_status  ...  \\\n",
      "0                1  female   251.967241            NaN  ...   \n",
      "1                2  female   257.925812            NaN  ...   \n",
      "2                3  female   248.033353        married  ...   \n",
      "3                4    male   221.426998        married  ...   \n",
      "4                5    male   102.958162       divorced  ...   \n",
      "\n",
      "   iter_total_working_years  iter_monthly_income    iter_salary  \\\n",
      "0                 11.318934         16280.830000  195370.000000   \n",
      "1                 34.000000          5697.600227  199990.000000   \n",
      "2                 22.000000          5697.600227  192320.000000   \n",
      "3                 11.318934         14307.500000  171690.000000   \n",
      "4                 11.318934         12783.920000   65245.875313   \n",
      "\n",
      "  knn_hourly_rate  knn_total_working_years knn_monthly_income     knn_salary  \\\n",
      "0       83.042302                11.318934       16280.830000  195370.000000   \n",
      "1       83.042302                34.000000        5697.600227  199990.000000   \n",
      "2       83.042302                22.000000        5697.600227  192320.000000   \n",
      "3       83.042302                11.318934       14307.500000  171690.000000   \n",
      "4       83.042302                11.318934       12783.920000   65245.875313   \n",
      "\n",
      "   typology_id  satisfaction_id  department_role_id  \n",
      "0           11            13333                  31  \n",
      "1           21            33213                  32  \n",
      "2          221            34343                 132  \n",
      "3          212            13323                  21  \n",
      "4           22            11443                  23  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adding the data from employee.csv - data on employees\n",
    "engine_route = 'mysql+mysqlconnector://root:AlumnaAdalab@127.0.0.1/project_talent'\n",
    "location = 'employees.csv'\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(engine_route)\n",
    "# Uppload the CSV file in a DataFrame \n",
    "df = pd.read_csv(location)\n",
    "# Verify that the first registries are in order\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e6c743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1614"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send the data to \n",
    "df.to_sql(\"employees\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa531eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category_travel  travel_id category_std_hours  std_hours_id category_remote  \\\n",
      "0      non_travel        1.0          full_time             1             yes   \n",
      "1      non_travel        1.0          full_time             1              no   \n",
      "2      non_travel        1.0          part_time             2             yes   \n",
      "3      non_travel        1.0          part_time             2              no   \n",
      "4   travel_rarely        2.0          full_time             1             yes   \n",
      "\n",
      "   remote_id  typology_id                              typology  \n",
      "0          1          111     non_travel, full_time, yes remote  \n",
      "1          2          112      non_travel, full_time, no remote  \n",
      "2          1          121     non_travel, part_time, yes remote  \n",
      "3          2          122      non_travel, part_time, no remote  \n",
      "4          1          211  travel_rarely, full_time, yes remote  \n"
     ]
    }
   ],
   "source": [
    "# Adding the data from typologies.csv - data on employment characteristics\n",
    "engine_route = 'mysql+mysqlconnector://root:AlumnaAdalab@127.0.0.1/project_talent'\n",
    "location = 'typologies.csv'\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(engine_route)\n",
    "# Uppload the CSV file in a DataFrame \n",
    "df = pd.read_csv(location)\n",
    "# Verify that the first registries are in order\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e7cd212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\"typologies\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67093788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category_environment  environment_id category_job_satisfaction  \\\n",
      "0                  low             1.0                       low   \n",
      "1                  low             1.0                       low   \n",
      "2                  low             1.0                       low   \n",
      "3                  low             1.0                       low   \n",
      "4                  low             1.0                       low   \n",
      "\n",
      "   job_satisfaction_id category_job_involvment  job_involvment_id  \\\n",
      "0                    1                     low                  1   \n",
      "1                    1                     low                  1   \n",
      "2                    1                     low                  1   \n",
      "3                    1                     low                  1   \n",
      "4                    1                     low                  1   \n",
      "\n",
      "  category_relationship  relationship_id category_balance  balance_id  \\\n",
      "0                   low                1         very_low           1   \n",
      "1                   low                1              low           2   \n",
      "2                   low                1             good           3   \n",
      "3                   low                1        excellent           4   \n",
      "4                medium                2         very_low           1   \n",
      "\n",
      "   satisfaction_id                     satisfaction  \n",
      "0            11111     low, low, low, low, very_low  \n",
      "1            11112          low, low, low, low, low  \n",
      "2            11113         low, low, low, low, good  \n",
      "3            11114    low, low, low, low, excellent  \n",
      "4            11121  low, low, low, medium, very_low  \n"
     ]
    }
   ],
   "source": [
    "# Adding the data from satisfaction_involment.csv - data on satisfaction metrics\n",
    "engine_route = 'mysql+mysqlconnector://root:AlumnaAdalab@127.0.0.1/project_talent'\n",
    "location = 'satisfaction_involvment.csv'\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(engine_route)\n",
    "# Uppload the CSV file in a DataFrame \n",
    "df = pd.read_csv(location)\n",
    "# Verify that the first registries are in order\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ae34d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\"satisfaction_involvment\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      category_department  department_id category_level  level_id  \\\n",
      "0  research_&_development            1.0    entry_level         1   \n",
      "1  research_&_development            1.0    entry_level         1   \n",
      "2  research_&_development            1.0    entry_level         1   \n",
      "3  research_&_development            1.0    entry_level         1   \n",
      "4  research_&_development            1.0    entry_level         1   \n",
      "\n",
      "            category_role  role_id  department_role_id  \\\n",
      "0       research_director        1                 111   \n",
      "1                 manager        2                 112   \n",
      "2         sales_executive        3                 113   \n",
      "3  manufacturing_director        4                 114   \n",
      "4      research_scientist        5                 115   \n",
      "\n",
      "                                     department_role  \n",
      "0  research_&_development, entry_level, research_...  \n",
      "1       research_&_development, entry_level, manager  \n",
      "2  research_&_development, entry_level, sales_exe...  \n",
      "3  research_&_development, entry_level, manufactu...  \n",
      "4  research_&_development, entry_level, research_...  \n"
     ]
    }
   ],
   "source": [
    "# Adding the data from department_role.csv - data on department and role classified\n",
    "engine_route = 'mysql+mysqlconnector://root:AlumnaAdalab@127.0.0.1/project_talent'\n",
    "location = 'department_role.csv'\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(engine_route)\n",
    "# Uppload the CSV file in a DataFrame \n",
    "df = pd.read_csv(location)\n",
    "# Verify that the first registries are in order\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "024aa61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\"department_role\", engine, if_exists=\"append\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
