{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cac8e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0629a2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "attrition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "business_travel",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "daily_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "department",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "distance_from_home",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education_field",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "employee_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "environment_satisfaction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hourly_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "job_involvement",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_role",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_satisfaction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "marital_status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "monthly_income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "monthly_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_companies_worked",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "overtime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "percent_salary_hike",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "performance_rating",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "relationship_satisfaction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "standard_hours",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stock_option_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_working_years",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "training_times_last_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_life_balance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "years_at_company",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "years_since_last_promotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "years_with_curr_manager",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date_birth",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "salary",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "remote_work",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "iter_hourly_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iter_total_working_years",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iter_monthly_income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iter_salary",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "knn_hourly_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "knn_total_working_years",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "knn_monthly_income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "knn_salary",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "351afaac-8a19-42fd-a1d9-8b41855b88b2",
       "rows": [
        [
         "0",
         "51",
         "no",
         null,
         "2015.72",
         null,
         "6",
         "3",
         null,
         "1",
         "low",
         "female",
         "251.96724093925093",
         "high",
         "executive",
         "research_director",
         "high",
         null,
         "16280.83",
         "42330.17",
         "7",
         "no",
         "13",
         "3,0",
         "high",
         "full_time",
         "0",
         "30.03974379822701",
         "5",
         "good",
         "20",
         "15",
         "15",
         "1972",
         "195370.0",
         "yes",
         "83.042301980198",
         "11.318933823529411",
         "16280.83",
         "195370.0",
         "83.042301980198",
         "11.318933823529411",
         "16280.83",
         "195370.0"
        ],
        [
         "1",
         "52",
         "no",
         null,
         "2063.39",
         null,
         "1",
         "4",
         "life_sciences",
         "2",
         "high",
         "female",
         "257.92581201460246",
         "medium",
         "executive",
         "manager",
         "high",
         null,
         "17117.127782767457",
         "43331.17",
         "0",
         "no",
         "14",
         "3,0",
         "low",
         "part_time",
         "1",
         "34.0",
         "5",
         "good",
         "33",
         "11",
         "9",
         "1971",
         "199990.0",
         "yes",
         "83.042301980198",
         "34.0",
         "5697.60022687609",
         "199990.0",
         "83.042301980198",
         "34.0",
         "5697.60022687609",
         "199990.0"
        ],
        [
         "2",
         "42",
         "no",
         "travel_rarely",
         "1984.25",
         "research_&_development",
         "4",
         "2",
         "technical_degree",
         "3",
         "high",
         "female",
         "248.0333527886016",
         "high",
         "executive",
         "manager",
         "very_high",
         "married",
         "16468.2521203622",
         "41669.33",
         "1",
         "no",
         "11",
         "3,0",
         "very_high",
         "part_time",
         "0",
         "22.0",
         "3",
         "good",
         "22",
         "11",
         "15",
         "1981",
         "192320.0",
         "yes",
         "83.042301980198",
         "22.0",
         "5697.60022687609",
         "192320.0",
         "83.042301980198",
         "22.0",
         "5697.60022687609",
         "192320.0"
        ],
        [
         "3",
         "47",
         "no",
         "travel_rarely",
         "1771.4",
         null,
         "2",
         "4",
         "medical",
         "4",
         "low",
         "male",
         "221.42699808455063",
         "high",
         "manager",
         "research_director",
         "high",
         "married",
         "14307.5",
         "37199.5",
         "3",
         "no",
         "19",
         "3,0",
         "medium",
         "full_time",
         "2",
         "26.672706874982943",
         "2",
         "good",
         "20",
         "5",
         "6",
         "1976",
         "171690.0",
         "no",
         "83.042301980198",
         "11.318933823529411",
         "14307.5",
         "171690.0",
         "83.042301980198",
         "11.318933823529411",
         "14307.5",
         "171690.0"
        ],
        [
         "4",
         "46",
         "no",
         null,
         "1582.77",
         null,
         "3",
         "3",
         "technical_degree",
         "5",
         "low",
         "male",
         "102.95816226378092",
         "very_high",
         "manager",
         "sales_executive",
         "low",
         "divorced",
         "12783.92",
         "33238.2",
         "2",
         "no",
         "12",
         "3,0",
         "very_high",
         "part_time",
         "1",
         "11.260714768989104",
         "5",
         "good",
         "19",
         "2",
         "8",
         "1977",
         "79832.80474607903",
         "no",
         "83.042301980198",
         "11.318933823529411",
         "12783.92",
         "65245.87531343283",
         "83.042301980198",
         "11.318933823529411",
         "12783.92",
         "65245.87531343283"
        ]
       ],
       "shape": {
        "columns": 43,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>attrition</th>\n",
       "      <th>business_travel</th>\n",
       "      <th>daily_rate</th>\n",
       "      <th>department</th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>education</th>\n",
       "      <th>education_field</th>\n",
       "      <th>employee_number</th>\n",
       "      <th>environment_satisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>salary</th>\n",
       "      <th>remote_work</th>\n",
       "      <th>iter_hourly_rate</th>\n",
       "      <th>iter_total_working_years</th>\n",
       "      <th>iter_monthly_income</th>\n",
       "      <th>iter_salary</th>\n",
       "      <th>knn_hourly_rate</th>\n",
       "      <th>knn_total_working_years</th>\n",
       "      <th>knn_monthly_income</th>\n",
       "      <th>knn_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>195370.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>16280.830000</td>\n",
       "      <td>195370.000000</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>16280.830000</td>\n",
       "      <td>195370.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2063.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>life_sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>199990.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>5697.600227</td>\n",
       "      <td>199990.000000</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>5697.600227</td>\n",
       "      <td>199990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>no</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>1984.25</td>\n",
       "      <td>research_&amp;_development</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>technical_degree</td>\n",
       "      <td>3</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>192320.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5697.600227</td>\n",
       "      <td>192320.000000</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5697.600227</td>\n",
       "      <td>192320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>no</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>1771.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>medical</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>171690.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>14307.500000</td>\n",
       "      <td>171690.000000</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>14307.500000</td>\n",
       "      <td>171690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1582.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>technical_degree</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>79832.804746</td>\n",
       "      <td>no</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>12783.920000</td>\n",
       "      <td>65245.875313</td>\n",
       "      <td>83.042302</td>\n",
       "      <td>11.318934</td>\n",
       "      <td>12783.920000</td>\n",
       "      <td>65245.875313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age attrition business_travel  daily_rate              department  \\\n",
       "0   51        no             NaN     2015.72                     NaN   \n",
       "1   52        no             NaN     2063.39                     NaN   \n",
       "2   42        no   travel_rarely     1984.25  research_&_development   \n",
       "3   47        no   travel_rarely     1771.40                     NaN   \n",
       "4   46        no             NaN     1582.77                     NaN   \n",
       "\n",
       "   distance_from_home  education   education_field  employee_number  \\\n",
       "0                   6          3               NaN                1   \n",
       "1                   1          4     life_sciences                2   \n",
       "2                   4          2  technical_degree                3   \n",
       "3                   2          4           medical                4   \n",
       "4                   3          3  technical_degree                5   \n",
       "\n",
       "  environment_satisfaction  ...         salary  remote_work iter_hourly_rate  \\\n",
       "0                      low  ...  195370.000000          yes        83.042302   \n",
       "1                     high  ...  199990.000000          yes        83.042302   \n",
       "2                     high  ...  192320.000000          yes        83.042302   \n",
       "3                      low  ...  171690.000000           no        83.042302   \n",
       "4                      low  ...   79832.804746           no        83.042302   \n",
       "\n",
       "  iter_total_working_years iter_monthly_income    iter_salary knn_hourly_rate  \\\n",
       "0                11.318934        16280.830000  195370.000000       83.042302   \n",
       "1                34.000000         5697.600227  199990.000000       83.042302   \n",
       "2                22.000000         5697.600227  192320.000000       83.042302   \n",
       "3                11.318934        14307.500000  171690.000000       83.042302   \n",
       "4                11.318934        12783.920000   65245.875313       83.042302   \n",
       "\n",
       "   knn_total_working_years  knn_monthly_income     knn_salary  \n",
       "0                11.318934        16280.830000  195370.000000  \n",
       "1                34.000000         5697.600227  199990.000000  \n",
       "2                22.000000         5697.600227  192320.000000  \n",
       "3                11.318934        14307.500000  171690.000000  \n",
       "4                11.318934        12783.920000   65245.875313  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23867e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'attrition', 'business_travel', 'daily_rate', 'department',\n",
       "       'distance_from_home', 'education', 'education_field', 'employee_number',\n",
       "       'environment_satisfaction', 'gender', 'hourly_rate', 'job_involvement',\n",
       "       'job_level', 'job_role', 'job_satisfaction', 'marital_status',\n",
       "       'monthly_income', 'monthly_rate', 'num_companies_worked', 'overtime',\n",
       "       'percent_salary_hike', 'performance_rating',\n",
       "       'relationship_satisfaction', 'standard_hours', 'stock_option_level',\n",
       "       'total_working_years', 'training_times_last_year', 'work_life_balance',\n",
       "       'years_at_company', 'years_since_last_promotion',\n",
       "       'years_with_curr_manager', 'date_birth', 'salary', 'remote_work',\n",
       "       'iter_hourly_rate', 'iter_total_working_years', 'iter_monthly_income',\n",
       "       'iter_salary', 'knn_hourly_rate', 'knn_total_working_years',\n",
       "       'knn_monthly_income', 'knn_salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8dd988",
   "metadata": {},
   "source": [
    "# Creating tables\n",
    "\n",
    "Table 1 - Employees (primary_key: employee_number)    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 4 - education: education_id + education_category  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 5 - education_field: education_field_id + education_field  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 7 - gender: gender_id + gender  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 10 - marital_status: marital_status_id + marital_status  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 12 - stock_option_level: stock_option_level_id + stock_option_level (numerica)\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tables - Salaries  \n",
    "\n",
    "->Table 2 - Identificador de trabajos Tipologias de trabajo  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 2 - business_travel: business_travel_id + business_travel_category  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 11 - standard_hours: standard_hours_id + standard_hours_category     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table - Remote work\n",
    "\n",
    "-> Table 3 - scale_1_4: scale_id + scale_level  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; environment_satisfaction   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; job_satisfaction  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; relationship_satisfaction   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; job_involvement  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 13 - work_life_balance: work_life_balance_id + work_life_balance_category    \n",
    "\n",
    "-> Table 4 - Department_Role  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 3 - department: department_id + department_name  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 8 - job_level: job_level_id + job_level  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Table 9 - job_role: job_role_id + job_role  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28908598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    travel_id  std_hours_id  remote_id  typology_id  \\\n",
      "0           1             1          1          111   \n",
      "1           1             1          2          112   \n",
      "2           1             2          1          121   \n",
      "3           1             2          2          122   \n",
      "4           2             1          1          211   \n",
      "5           2             1          2          212   \n",
      "6           2             2          1          221   \n",
      "7           2             2          2          222   \n",
      "8           3             1          1          311   \n",
      "9           3             1          2          312   \n",
      "10          3             2          1          321   \n",
      "11          3             2          2          322   \n",
      "12       <NA>             1          1           11   \n",
      "13       <NA>             1          2           12   \n",
      "14       <NA>             2          1           21   \n",
      "15       <NA>             2          2           22   \n",
      "\n",
      "                                    typology  \n",
      "0          non_travel, full_time, yes remote  \n",
      "1           non_travel, full_time, no remote  \n",
      "2          non_travel, part_time, yes remote  \n",
      "3           non_travel, part_time, no remote  \n",
      "4       travel_rarely, full_time, yes remote  \n",
      "5        travel_rarely, full_time, no remote  \n",
      "6       travel_rarely, part_time, yes remote  \n",
      "7        travel_rarely, part_time, no remote  \n",
      "8   travel_frequently, full_time, yes remote  \n",
      "9    travel_frequently, full_time, no remote  \n",
      "10  travel_frequently, part_time, yes remote  \n",
      "11   travel_frequently, part_time, no remote  \n",
      "12                     full_time, yes remote  \n",
      "13                      full_time, no remote  \n",
      "14                     part_time, yes remote  \n",
      "15                      part_time, no remote  \n"
     ]
    }
   ],
   "source": [
    "# Table 2 - Work Typologies\n",
    "# Create list of the typologies characteristics\n",
    "categories1 = df['business_travel'].unique().tolist()\n",
    "categories2 = df['standard_hours'].unique().tolist()\n",
    "categories3 = df['remote_work'].unique().tolist()\n",
    "\n",
    "# Create DataFrames (df) based on the litsts\n",
    "work_typologies1 = pd.DataFrame({'category_travel': categories1})\n",
    "work_typologies2 = pd.DataFrame({'category_std_hours': categories2})\n",
    "work_typologies3 = pd.DataFrame({'category_remote': categories3})\n",
    "\n",
    "# Create a mapping order for the characteristics\n",
    "order_mapping1 = {'non_travel': 1, 'travel_rarely': 2, 'travel_frequently': 3, 'NaN': 4}\n",
    "order_mapping2 = {'full_time': 1, 'part_time': 2, 'NaN': 3}\n",
    "order_mapping3 = {'yes': 1, 'no': 2, 'NaN': 3}\n",
    "\n",
    "# Sort using custom mapping\n",
    "work_typologies1 = work_typologies1.assign(sort_order = lambda work_typologies1: work_typologies1['category_travel'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "work_typologies2 = work_typologies2.assign(sort_order = lambda work_typologies2: work_typologies2['category_std_hours'].map(order_mapping2)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "work_typologies3 = work_typologies3.assign(sort_order = lambda work_typologies3: work_typologies3['category_remote'].map(order_mapping3)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "\n",
    "# Assign an _id\n",
    "work_typologies1.loc[work_typologies1['category_travel'] == 'non_travel', 'travel_id'] = 1\n",
    "work_typologies1.loc[work_typologies1['category_travel'] == 'travel_rarely', 'travel_id'] = 2\n",
    "work_typologies1.loc[work_typologies1['category_travel'] == 'travel_frequently', 'travel_id'] = 3\n",
    "\n",
    "work_typologies2.loc[work_typologies2['category_std_hours'] == 'full_time', 'std_hours_id'] = 1\n",
    "work_typologies2.loc[work_typologies2['category_std_hours'] == 'part_time', 'std_hours_id'] = 2\n",
    "\n",
    "\n",
    "work_typologies3.loc[work_typologies3['category_remote'] == 'yes', 'remote_id'] = 1\n",
    "work_typologies3.loc[work_typologies3['category_remote'] == 'no', 'remote_id'] = 2\n",
    "\n",
    "# Round _id, allowing for NaN values\n",
    "work_typologies1['travel_id'] = work_typologies1['travel_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "work_typologies2['std_hours_id'] = work_typologies2['std_hours_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "work_typologies3['remote_id'] = work_typologies3['remote_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "\n",
    "# Combine the characteristics\n",
    "cross_joined_df1 = work_typologies1.merge(work_typologies2, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df1.merge(work_typologies3, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df2.drop_duplicates()\n",
    "\n",
    "# Create typology_id based on characteristics' categories_id\n",
    "cross_joined_df2['typology_id'] = cross_joined_df2['travel_id']*100 + cross_joined_df2['std_hours_id']*10 + cross_joined_df2['remote_id'] \n",
    "mask = pd.isna(cross_joined_df2['typology_id'])\n",
    "cross_joined_df2.loc[mask, 'typology_id'] = (cross_joined_df2.loc[mask, 'std_hours_id'] * 10 + cross_joined_df2.loc[mask, 'remote_id'])\n",
    "\n",
    "# Create typology based on characteristics' categories\n",
    "cross_joined_df2['typology'] = cross_joined_df2['category_travel'] + ', ' + cross_joined_df2['category_std_hours']+ ', ' + cross_joined_df2['category_remote'] +' remote' \n",
    "mask = pd.isna(cross_joined_df2['typology'])\n",
    "cross_joined_df2.loc[mask, 'typology'] = (cross_joined_df2.loc[mask, 'category_std_hours'] + ', ' + cross_joined_df2.loc[mask, 'category_remote'] +' remote')\n",
    "\n",
    "print(cross_joined_df2[['travel_id','std_hours_id','remote_id','typology_id','typology']])\n",
    "\n",
    "table2 = cross_joined_df2.copy()\n",
    "table2.to_csv(\"typologies.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c774935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 - Satisfaction_and_involvment\n",
    "# Create list of the satisfaction characteristics\n",
    "categories1 = df['environment_satisfaction'].unique().tolist()\n",
    "categories2 = df['job_satisfaction'].unique().tolist()\n",
    "categories3 = df['job_involvement'].unique().tolist()\n",
    "categories4 = df['relationship_satisfaction'].unique().tolist()\n",
    "categories5 = df['work_life_balance'].unique().tolist()\n",
    "\n",
    "# Create DataFrames (df) based on the litsts\n",
    "satisfaction_typologies1 = pd.DataFrame({'category_environment': categories1})\n",
    "satisfaction_typologies2 = pd.DataFrame({'category_job_satisfaction': categories2})\n",
    "satisfaction_typologies3 = pd.DataFrame({'category_job_involvment': categories3})\n",
    "satisfaction_typologies4 = pd.DataFrame({'category_relationship': categories4})\n",
    "satisfaction_typologies5 = pd.DataFrame({'category_balance': categories5})\n",
    "\n",
    "# Create a mapping order for the characteristics\n",
    "order_mapping1 = {'low': 1, 'medium': 2, 'high': 3, 'very_high': 4, 'NaN': 5}\n",
    "order_mapping5 = {'very_low': 1, 'low': 2, 'good': 3, 'excellent': 4, 'NaN': 5}\n",
    "\n",
    "# Sort using custom mapping\n",
    "satisfaction_typologies1 = satisfaction_typologies1.assign(sort_order = lambda satisfaction_typologies1: satisfaction_typologies1['category_environment'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "satisfaction_typologies2 = satisfaction_typologies2.assign(sort_order = lambda satisfaction_typologies2: satisfaction_typologies2['category_job_satisfaction'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "satisfaction_typologies3 = satisfaction_typologies3.assign(sort_order = lambda satisfaction_typologies3: satisfaction_typologies3['category_job_involvment'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "satisfaction_typologies4 = satisfaction_typologies4.assign(sort_order = lambda satisfaction_typologies4: satisfaction_typologies4['category_relationship'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "satisfaction_typologies5 = satisfaction_typologies5.assign(sort_order = lambda satisfaction_typologies5: satisfaction_typologies5['category_balance'].map(order_mapping5)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "\n",
    "# Assign an _id\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'low', 'environment_id'] = 1\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'medium', 'environment_id'] = 2\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'high', 'environment_id'] = 3\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'very_high', 'environment_id'] = 4\n",
    "satisfaction_typologies1.loc[satisfaction_typologies1['category_environment'] == 'NaN', 'environment_id'] = 5\n",
    "\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'low', 'job_satisfaction_id'] = 1\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'medium', 'job_satisfaction_id'] = 2\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'high', 'job_satisfaction_id'] = 3\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'very_high', 'job_satisfaction_id'] = 4\n",
    "satisfaction_typologies2.loc[satisfaction_typologies2['category_job_satisfaction'] == 'NaN', 'job_satisfaction_id'] = 5\n",
    "\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'low', 'job_involvment_id'] = 1\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'medium', 'job_involvment_id'] = 2\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'high', 'job_involvment_id'] = 3\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'very_high', 'job_involvment_id'] = 4\n",
    "satisfaction_typologies3.loc[satisfaction_typologies3['category_job_involvment'] == 'NaN', 'job_involvment_id'] = 5\n",
    "\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'low', 'relationship_id'] = 1\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'medium', 'relationship_id'] = 2\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'high', 'relationship_id'] = 3\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'very_high', 'relationship_id'] = 4\n",
    "satisfaction_typologies4.loc[satisfaction_typologies4['category_relationship'] == 'NaN', 'relationship_id'] = 4\n",
    "\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'very_low', 'balance_id'] = 1\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'low', 'balance_id'] = 2\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'good', 'balance_id'] = 3\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'excellent', 'balance_id'] = 4\n",
    "satisfaction_typologies5.loc[satisfaction_typologies5['category_balance'] == 'NaN', 'balance_id'] = 5\n",
    "\n",
    "# Round _id, allowing for NaN values\n",
    "satisfaction_typologies1['environment_id'] = satisfaction_typologies1['environment_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "satisfaction_typologies2['job_satisfaction_id'] = satisfaction_typologies2['job_satisfaction_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "satisfaction_typologies3['job_involvment_id'] = satisfaction_typologies3['job_involvment_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "satisfaction_typologies4['relationship_id'] = satisfaction_typologies4['relationship_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "satisfaction_typologies5['balance_id'] = satisfaction_typologies5['balance_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "\n",
    "# Combine the characteristics\n",
    "cross_joined_df1 = satisfaction_typologies1.merge(satisfaction_typologies2, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df1.merge(satisfaction_typologies3, how = 'cross')\n",
    "cross_joined_df3 = cross_joined_df2.merge(satisfaction_typologies4, how = 'cross')\n",
    "cross_joined_df4 = cross_joined_df3.merge(satisfaction_typologies5, how = 'cross')\n",
    "cross_joined_df4 = cross_joined_df4.drop_duplicates()\n",
    "\n",
    "# Create typology_id based on characteristics' categories_id\n",
    "cross_joined_df4['satisfaction_id'] = (cross_joined_df4['environment_id']*10000 + cross_joined_df4['job_satisfaction_id']*1000 + cross_joined_df4['job_involvment_id']*100 + \n",
    "                                       cross_joined_df4['relationship_id']*10 + cross_joined_df4['balance_id']*1)\n",
    "mask = pd.isna(cross_joined_df4['satisfaction_id'])\n",
    "cross_joined_df4.loc[mask, 'satisfaction_id'] = (cross_joined_df4.loc[mask, 'job_satisfaction_id'] * 1000 + cross_joined_df4.loc[mask, 'job_involvment_id']*100 + \n",
    "                                             cross_joined_df4.loc[mask, 'relationship_id'] * 10 + cross_joined_df4.loc[mask, 'balance_id'] * 1)\n",
    "\n",
    "# Create typology based on characteristics' categories\n",
    "cross_joined_df4['satisfaction'] = (cross_joined_df4['category_environment'] + ', ' + cross_joined_df4['category_job_satisfaction']+ ', ' + cross_joined_df4['category_job_involvment'] +\n",
    "                                    ', ' + cross_joined_df4['category_relationship']+ ', ' + cross_joined_df4['category_balance'])\n",
    "mask = pd.isna(cross_joined_df4['satisfaction'])\n",
    "cross_joined_df4.loc[mask, 'satisfaction'] = ('environment_missing' + ' ,' + cross_joined_df4.loc[mask, 'category_job_satisfaction'] + ', ' + cross_joined_df4.loc[mask, 'category_job_involvment'] +\n",
    "                                              ', ' + cross_joined_df4.loc[mask, 'category_relationship'] + ', ' + cross_joined_df4.loc[mask, 'category_balance'])\n",
    "\n",
    "cross_joined_df4[['environment_id','job_satisfaction_id','job_involvment_id','relationship_id','balance_id', 'satisfaction_id', 'satisfaction']]\n",
    "\n",
    "table3 = cross_joined_df4.copy()\n",
    "table3.to_csv(\"satisfaction_involvment.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23347aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     department_id  level_id  role_id  department_role_id  \\\n",
      "0                1         1        1                 111   \n",
      "1                1         1        2                 112   \n",
      "2                1         1        3                 113   \n",
      "3                1         1        4                 114   \n",
      "4                1         1        5                 115   \n",
      "..             ...       ...      ...                 ...   \n",
      "175           <NA>         5        5                  55   \n",
      "176           <NA>         5        6                  56   \n",
      "177           <NA>         5        7                  57   \n",
      "178           <NA>         5        8                  58   \n",
      "179           <NA>         5        9                  59   \n",
      "\n",
      "                                       department_role  \n",
      "0    research_&_development, entry_level, research_...  \n",
      "1         research_&_development, entry_level, manager  \n",
      "2    research_&_development, entry_level, sales_exe...  \n",
      "3    research_&_development, entry_level, manufactu...  \n",
      "4    research_&_development, entry_level, research_...  \n",
      "..                                                 ...  \n",
      "175                         senior, research_scientist  \n",
      "176                  senior, healthcare_representative  \n",
      "177                      senior, laboratory_technician  \n",
      "178                       senior, sales_representative  \n",
      "179                            senior, human_resources  \n",
      "\n",
      "[180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Table 4 - Department_role\n",
    "# Create list of the department_role categories\n",
    "categories1 = df['department'].unique().tolist()\n",
    "categories2 = df['job_level'].unique().tolist()\n",
    "categories3 = df['job_role'].unique().tolist()\n",
    "\n",
    "# Create DataFrames (df) based on the litsts\n",
    "department_role1 = pd.DataFrame({'category_department': categories1})\n",
    "department_role2 = pd.DataFrame({'category_level': categories2})\n",
    "department_role3 = pd.DataFrame({'category_role': categories3})\n",
    "\n",
    "# Create a mapping order for the characteristics\n",
    "order_mapping1 = {'research_&_development': 1, 'sales': 2, 'human_resources': 3, 'NaN': 4}\n",
    "order_mapping2 = {'entry_level': 1, 'manager': 2, 'executive': 3, 'intermediate': 4, 'senior': 5, 'NaN': 6}\n",
    "order_mapping3 = {'research_director': 1, 'manager': 2, 'sales_executive': 3, 'manufacturing_director': 4, 'research_scientist': 5,\n",
    "                    'healthcare_representative': 6, 'laboratory_technician': 7, 'sales_representative': 8, 'human_resources': 9, 'NaN': 10}\n",
    "\n",
    "# Sort using custom mapping\n",
    "department_role1 = department_role1.assign(sort_order = lambda department_role1: department_role1['category_department'].map(order_mapping1)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "department_role2 = department_role2.assign(sort_order = lambda department_role2: department_role2['category_level'].map(order_mapping2)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "department_role3 = department_role3.assign(sort_order = lambda department_role3: department_role3['category_role'].map(order_mapping3)).sort_values('sort_order').drop('sort_order', axis=1)\n",
    "\n",
    "# Assign an _id\n",
    "department_role1.loc[department_role1['category_department'] == 'research_&_development', 'department_id'] = 1\n",
    "department_role1.loc[department_role1['category_department'] == 'sales', 'department_id'] = 2\n",
    "department_role1.loc[department_role1['category_department'] == 'human_resources', 'department_id'] = 3\n",
    "\n",
    "department_role2.loc[department_role2['category_level'] == 'entry_level', 'level_id'] = 1\n",
    "department_role2.loc[department_role2['category_level'] == 'manager', 'level_id'] = 2\n",
    "department_role2.loc[department_role2['category_level'] == 'executive', 'level_id'] = 3\n",
    "department_role2.loc[department_role2['category_level'] == 'intermediate', 'level_id'] = 4\n",
    "department_role2.loc[department_role2['category_level'] == 'senior', 'level_id'] = 5\n",
    "\n",
    "department_role3.loc[department_role3['category_role'] == 'research_director', 'role_id'] = 1\n",
    "department_role3.loc[department_role3['category_role'] == 'manager', 'role_id'] = 2\n",
    "department_role3.loc[department_role3['category_role'] == 'sales_executive', 'role_id'] = 3\n",
    "department_role3.loc[department_role3['category_role'] == 'manufacturing_director', 'role_id'] = 4\n",
    "department_role3.loc[department_role3['category_role'] == 'research_scientist', 'role_id'] = 5\n",
    "department_role3.loc[department_role3['category_role'] == 'healthcare_representative', 'role_id'] = 6\n",
    "department_role3.loc[department_role3['category_role'] == 'laboratory_technician', 'role_id'] = 7\n",
    "department_role3.loc[department_role3['category_role'] == 'sales_representative', 'role_id'] = 8\n",
    "department_role3.loc[department_role3['category_role'] == 'human_resources', 'role_id'] = 9\n",
    "\n",
    "# Round _id, allowing for NaN values\n",
    "department_role1['department_id'] = department_role1['department_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "department_role2['level_id'] = department_role2['level_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "department_role3['role_id'] = department_role3['role_id'].round().astype('Int64') # Use 'Int64' to handle NaN values\n",
    "\n",
    "# Combine the characteristics\n",
    "cross_joined_df1 = department_role1.merge(department_role2, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df1.merge(department_role3, how = 'cross')\n",
    "cross_joined_df2 = cross_joined_df2.drop_duplicates()\n",
    "\n",
    "# Create typology_id based on characteristics' categories_id\n",
    "cross_joined_df2['department_role_id'] = cross_joined_df2['department_id']*100 + cross_joined_df2['level_id']*10 + cross_joined_df2['role_id'] \n",
    "mask = pd.isna(cross_joined_df2['department_role_id'])\n",
    "cross_joined_df2.loc[mask, 'department_role_id'] = (cross_joined_df2.loc[mask, 'level_id'] * 10 + cross_joined_df2.loc[mask, 'role_id'])\n",
    "\n",
    "# Create typology based on characteristics' categories\n",
    "cross_joined_df2['department_role'] = cross_joined_df2['category_department'] + ', ' + cross_joined_df2['category_level']+ ', ' + cross_joined_df2['category_role'] \n",
    "mask = pd.isna(cross_joined_df2['department_role'])\n",
    "cross_joined_df2.loc[mask, 'department_role'] = (cross_joined_df2.loc[mask, 'category_level'] + ', ' + cross_joined_df2.loc[mask, 'category_role'])\n",
    "\n",
    "print(cross_joined_df2[['department_id','level_id','role_id','department_role_id','department_role']])\n",
    "\n",
    "table4 = cross_joined_df2.copy() \n",
    "table4.to_csv(\"department_role.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cff720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1\n",
    "df_employees = df.copy()\n",
    "df_employees.columns\n",
    "df_employees.rename(columns={\"business_travel\": \"category_travel\", \"standard_hours\": \"category_std_hours\", 'remote_work': 'category_remote',\n",
    "                   'environment_satisfaction': 'category_environment', 'job_satisfaction': 'category_job_satisfaction', 'job_involvement': 'category_job_involvment',\n",
    "                   'relationship_satisfaction': 'category_relationship', 'work_life_balance': 'category_balance',\n",
    "                   'department': 'category_department', 'job_level': 'category_level', 'job_role': 'category_role'}, inplace=True)\n",
    "\n",
    "\n",
    "df_employees = df_employees.merge(table2, on=['category_travel', 'category_std_hours', 'category_remote'], how='left')\n",
    "df_employees = df_employees.merge(table3, on=['category_environment', 'category_job_satisfaction', 'category_job_involvment', 'category_relationship', 'category_balance'], how='left')\n",
    "df_employees = df_employees.merge(table4, on=['category_department', 'category_level', 'category_role'], how='left')\n",
    "\n",
    "\n",
    "df_employees = df_employees.loc[:, ~df_employees.columns.str.startswith('category_')]\n",
    "\n",
    "columns = ['travel_id', 'std_hours_id', 'remote_id','environment_id', 'job_satisfaction_id', 'job_involvment_id','relationship_id',\n",
    "           'balance_id', 'department_id', 'level_id', 'role_id', 'typology','satisfaction','department_role']\n",
    "df_employees = df_employees.drop(columns=columns)\n",
    "\n",
    "table1 = df_employees.copy() \n",
    "table1.to_csv(\"employees.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "088dc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'root'\n",
    "password = 'AlumnaAdalab'\n",
    "host = '127.0.0.1'\n",
    "\n",
    "# Try the connection and check the error message and code in case it is not working\n",
    "try:\n",
    "  cnx = mysql.connector.connect(user = user, password = password,\n",
    "                                host = host)\n",
    "except mysql.connector.Error as err:\n",
    "  if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "    print(\"Something is wrong with your user name or password\")\n",
    "  elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "    print(\"Database does not exist\")\n",
    "  else:\n",
    "    print(err)\n",
    "else:\n",
    "  cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55ea88c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'project_talent' dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Connection parameters\n",
    "user = 'root'\n",
    "password = 'AlumnaAdalab'\n",
    "host = '127.0.0.1'\n",
    "\n",
    "# Connect to MySQL server\n",
    "cnx = mysql.connector.connect(user=user, password=password, host=host)\n",
    "mycursor = cnx.cursor()\n",
    "\n",
    "# Try to drop the database\n",
    "try:\n",
    "    mycursor.execute(\"DROP DATABASE project_talent\")\n",
    "    print(\"Database 'project_talent' dropped successfully.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Failed to drop database:\")\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)\n",
    "\n",
    "# Close connection\n",
    "mycursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddee0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMySQLCursor: CREATE DATABASE project_talent\n"
     ]
    }
   ],
   "source": [
    "user = 'root'\n",
    "password = 'AlumnaAdalab'\n",
    "host = '127.0.0.1'\n",
    "\n",
    "# conexión (1)\n",
    "cnx = mysql.connector.connect(user = user, password = password,\n",
    "                              host = host)\n",
    "\n",
    "# cursor (2)\n",
    "mycursor = cnx.cursor()\n",
    "\n",
    "try:\n",
    "    mycursor.execute(\"CREATE DATABASE project_talent\")\n",
    "    print(mycursor)\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a3fec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age attrition  daily_rate  distance_from_home  education   education_field  \\\n",
      "0   51        no     2015.72                   6          3               NaN   \n",
      "1   52        no     2063.39                   1          4     life_sciences   \n",
      "2   42        no     1984.25                   4          2  technical_degree   \n",
      "3   47        no     1771.40                   2          4           medical   \n",
      "4   46        no     1582.77                   3          3  technical_degree   \n",
      "\n",
      "   employee_number  gender  hourly_rate marital_status  ...  \\\n",
      "0                1  female   251.967241            NaN  ...   \n",
      "1                2  female   257.925812            NaN  ...   \n",
      "2                3  female   248.033353        married  ...   \n",
      "3                4    male   221.426998        married  ...   \n",
      "4                5    male   102.958162       divorced  ...   \n",
      "\n",
      "   iter_total_working_years  iter_monthly_income    iter_salary  \\\n",
      "0                 11.318934         16280.830000  195370.000000   \n",
      "1                 34.000000          5697.600227  199990.000000   \n",
      "2                 22.000000          5697.600227  192320.000000   \n",
      "3                 11.318934         14307.500000  171690.000000   \n",
      "4                 11.318934         12783.920000   65245.875313   \n",
      "\n",
      "  knn_hourly_rate  knn_total_working_years knn_monthly_income     knn_salary  \\\n",
      "0       83.042302                11.318934       16280.830000  195370.000000   \n",
      "1       83.042302                34.000000        5697.600227  199990.000000   \n",
      "2       83.042302                22.000000        5697.600227  192320.000000   \n",
      "3       83.042302                11.318934       14307.500000  171690.000000   \n",
      "4       83.042302                11.318934       12783.920000   65245.875313   \n",
      "\n",
      "   typology_id  satisfaction_id  department_role_id  \n",
      "0           11            13333                  31  \n",
      "1           21            33213                  32  \n",
      "2          221            34343                 132  \n",
      "3          212            13323                  21  \n",
      "4           22            11443                  23  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adding the data from employee.csv - data on employees\n",
    "engine_route = 'mysql+mysqlconnector://root:AlumnaAdalab@127.0.0.1/project_talent'\n",
    "location = 'C:\\\\Users\\\\aleiv\\\\Desktop\\\\Adalab\\\\da-promo-50-ana-leiva\\\\Modulo 3\\\\Proyecto\\\\project-da-promo-50-modulo-3-team-4\\\\employees.csv'\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(engine_route)\n",
    "# Uppload the CSV file in a DataFrame \n",
    "df = pd.read_csv(location)\n",
    "# Verify that the first registries are in order\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e6c743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1614"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send the data to \n",
    "df.to_sql(\"employees\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa531eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category_travel  travel_id category_std_hours  std_hours_id category_remote  \\\n",
      "0      non_travel        1.0          full_time             1             yes   \n",
      "1      non_travel        1.0          full_time             1              no   \n",
      "2      non_travel        1.0          part_time             2             yes   \n",
      "3      non_travel        1.0          part_time             2              no   \n",
      "4   travel_rarely        2.0          full_time             1             yes   \n",
      "\n",
      "   remote_id  typology_id                              typology  \n",
      "0          1          111     non_travel, full_time, yes remote  \n",
      "1          2          112      non_travel, full_time, no remote  \n",
      "2          1          121     non_travel, part_time, yes remote  \n",
      "3          2          122      non_travel, part_time, no remote  \n",
      "4          1          211  travel_rarely, full_time, yes remote  \n"
     ]
    }
   ],
   "source": [
    "# Adding the data from typologies.csv - data on employment characteristics\n",
    "engine_route = 'mysql+mysqlconnector://root:AlumnaAdalab@127.0.0.1/project_talent'\n",
    "location = 'C:\\\\Users\\\\aleiv\\\\Desktop\\\\Adalab\\\\da-promo-50-ana-leiva\\\\Modulo 3\\\\Proyecto\\\\project-da-promo-50-modulo-3-team-4\\\\typologies.csv'\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(engine_route)\n",
    "# Uppload the CSV file in a DataFrame \n",
    "df = pd.read_csv(location)\n",
    "# Verify that the first registries are in order\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e7cd212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\"typologies\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67093788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category_environment  environment_id category_job_satisfaction  \\\n",
      "0                  low             1.0                       low   \n",
      "1                  low             1.0                       low   \n",
      "2                  low             1.0                       low   \n",
      "3                  low             1.0                       low   \n",
      "4                  low             1.0                       low   \n",
      "\n",
      "   job_satisfaction_id category_job_involvment  job_involvment_id  \\\n",
      "0                    1                     low                  1   \n",
      "1                    1                     low                  1   \n",
      "2                    1                     low                  1   \n",
      "3                    1                     low                  1   \n",
      "4                    1                     low                  1   \n",
      "\n",
      "  category_relationship  relationship_id category_balance  balance_id  \\\n",
      "0                   low                1         very_low           1   \n",
      "1                   low                1              low           2   \n",
      "2                   low                1             good           3   \n",
      "3                   low                1        excellent           4   \n",
      "4                medium                2         very_low           1   \n",
      "\n",
      "   satisfaction_id                     satisfaction  \n",
      "0            11111     low, low, low, low, very_low  \n",
      "1            11112          low, low, low, low, low  \n",
      "2            11113         low, low, low, low, good  \n",
      "3            11114    low, low, low, low, excellent  \n",
      "4            11121  low, low, low, medium, very_low  \n"
     ]
    }
   ],
   "source": [
    "# Adding the data from satisfaction_involment.csv - data on satisfaction metrics\n",
    "engine_route = 'mysql+mysqlconnector://root:AlumnaAdalab@127.0.0.1/project_talent'\n",
    "location = 'C:\\\\Users\\\\aleiv\\\\Desktop\\\\Adalab\\\\da-promo-50-ana-leiva\\\\Modulo 3\\\\Proyecto\\\\project-da-promo-50-modulo-3-team-4\\\\satisfaction_involvment.csv'\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(engine_route)\n",
    "# Uppload the CSV file in a DataFrame \n",
    "df = pd.read_csv(location)\n",
    "# Verify that the first registries are in order\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ae34d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\"satisfaction_involvment\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      category_department  department_id category_level  level_id  \\\n",
      "0  research_&_development            1.0    entry_level         1   \n",
      "1  research_&_development            1.0    entry_level         1   \n",
      "2  research_&_development            1.0    entry_level         1   \n",
      "3  research_&_development            1.0    entry_level         1   \n",
      "4  research_&_development            1.0    entry_level         1   \n",
      "\n",
      "            category_role  role_id  department_role_id  \\\n",
      "0       research_director        1                 111   \n",
      "1                 manager        2                 112   \n",
      "2         sales_executive        3                 113   \n",
      "3  manufacturing_director        4                 114   \n",
      "4      research_scientist        5                 115   \n",
      "\n",
      "                                     department_role  \n",
      "0  research_&_development, entry_level, research_...  \n",
      "1       research_&_development, entry_level, manager  \n",
      "2  research_&_development, entry_level, sales_exe...  \n",
      "3  research_&_development, entry_level, manufactu...  \n",
      "4  research_&_development, entry_level, research_...  \n"
     ]
    }
   ],
   "source": [
    "# Adding the data from department_role.csv - data on department and role classified\n",
    "engine_route = 'mysql+mysqlconnector://root:AlumnaAdalab@127.0.0.1/project_talent'\n",
    "location = 'C:\\\\Users\\\\aleiv\\\\Desktop\\\\Adalab\\\\da-promo-50-ana-leiva\\\\Modulo 3\\\\Proyecto\\\\project-da-promo-50-modulo-3-team-4\\\\department_role.csv'\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(engine_route)\n",
    "# Uppload the CSV file in a DataFrame \n",
    "df = pd.read_csv(location)\n",
    "# Verify that the first registries are in order\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "024aa61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\"department_role\", engine, if_exists=\"append\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
